=========Tema 2 - Document processing using the paradigm map-reduced===========
===================================APD=========================================
==Chirac Andrei 335CC==

    === Tema2 class ===
        - Conduct all the result process by the other classes and manage the flow

    === Data class ===
        - This class is used for many things such as :
            * parse the input given
            * put in the output file the information that is required
            * creates the data that a worker will use in the Map stage
            * starts the execution process on Map operations
            * creates the data that a worker will use in the Reduce stage
            * starts the execution process on Reduce operations

    === Fragmentation class ===
        - This class will iterate through the files given in the input and take it
        apart in the wanted manner
        --------------------------------------------------------------------------
         Algoritmi Paraleli si Distribuiti

         • in1.txt, offset 0, dimensiune 10 (“Algoritmi ”)
         • in1.txt, offset 10, dimensiune 10 (“Paraleli s”)
         • in1.txt, offset 20, dimensiune 10 (“i Distribu”)
         • in1.txt, offset 30, dimensiune 3 (“iti”)
        --------------------------------------------------------------------------

    === Executor class ===
        - This class as the names says is based on the ExecutorService idea which
        allows us to execute tasks asynchronous
        - This class is used for three things :

            * Map stage in which we will use tasks that have been generated by the
             Data class

            * Process the data from the map stage and reappears it for the Reduce
            stage
            --------------------------------------------------------------------------
            • T1 → in1.txt; {9: 1}, {8: 1, 2: 1}, {11: 1}, {}; (“Algoritmi”) (“Paraleli”) (“Distribuiti”) ()
            --------------------------------------------------------------------------

            * Reduce stage that will provide the final answer based on the
            processed data from the Map stage
            --------------------------------------------------------------------------
            • T1 → in1.txt, 58.75 (rang), 11 (lungime maxima), 1 (cuvant cu acea lungime)
            --------------------------------------------------------------------------

    === TaskMap class ===
        - Will take care of the Map stage by processing the strings in the wanted
        manner, so to achieve this the class in its run method will do the
        following step:
            * each of the tasks that are solved by the threads will provide a
            dictionary with the dimensions of the words in a fragment and
            the number of their appearances as well as the word list of
            maximum size. This idea is based on 6 criteria such as :
                | we read the information using the given offset from the file
                 that was attributed to this task
                | we read in a variable the last character from the previous
                 sequence
                | we read in another variable the first character from the next
                 sequence
                ( with this information we will know if the word has ended in
                this sequence or not )
                | we will need to create our ward letter by letter like this :
                    @ if the word is the fist word from our current sequence it
                    can be part of another word, so we have to check if the
                    previous sequence has ended in that case we can concatenate
                    the letter and keep going until we get a separator that will
                    let us know that there is the end of the word and the
                    character that indicates what was previous will be changed
                    @ if the word is a regular word that is placed between
                    separators
                    @ in case we have reached the last word from a sequence,
                     there are two cases :
                        # the word might end there
                        # the word might be continued in another sequence so in
                        this case we will read until we will reach a separator
                        because that will indicate our end
                | after the processing we will need a semaphore because the
                threads are writing in the same place so it will pe a critical
                region
                | in the end we take out this task from the task pool by
                decrementing the queue that monitoring the number of unfinished
                tasks
        --------------------------------------------------------------------------
        • RT1 → in1.txt; {9: 1}; (“Algoritmi”)
        • RT2 → in1.txt; {8: 1, 2: 1}; (“Paraleli”)
        • RT3 → in1.txt; {11: 1}; (“Distribuiti”)
        • RT4 → in1.txt; {}; ()
        --------------------------------------------------------------------------

    === TaskReduce class ===
        - Will take care of the Reduce stage by processing the strings in the wanted
        manner, so to achieve this the class in its run method will do the
        following step:
            * each of the tasks that are solved by the threads will provide the
            final results (file name, the rank of each file, as well as the maximum
            word length in a file and the number of occurrences of words with that
            length) by doing this steps:
                | in order to get the longest word and calculate the rang we should
                iterate through each of the dictionary provided by the Merge tasks
                for this file, in order to do this in a variable we will store the
                sum off al words converted by the given formula and in another
                variable we will store the numbers of words that were found in the
                file
                | this results were stored in such a manner that we will not need
                to sort the results. The map is already sorted in descending order
                so we will need only the first element from it because that will
                indicate what is the length of the longest word and how many
                times words with such length had appeared in our file.
                | after the processing we will need a semaphore because the
                threads are writing in the same place so it will pe a critical
                region
                | in the end we take out this task from the task pool by
                decrementing the queue that monitoring the number of unfinished
                tasks

    === ResultTaskMap class ===
        - Is used for storing the partial result from each thread in the Map stage

    === FinalResultTaskMap class ===
        - It is used by the executor to put together for each file the data that
        has provided from each thread

    === FinalResultTaskReduce class ===
        - It is used to store the results in easy way for the data to get the final
        result